{
 "cells": [
  {
   "cell_type": "code",
   "id": "c1a46fd3b0556119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:20.743073Z",
     "start_time": "2025-11-18T10:52:16.252325Z"
    }
   },
   "source": [
    "import torch\n",
    "import jax\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tiny_imagenet_torch import TinyImageNet ## Import allow TinyImage via torch methods(64x64)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:21.448693Z",
     "start_time": "2025-11-18T10:52:20.755539Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Confirm cuda is enabled on both jax and torch\n",
    "print(torch.cuda.is_available())\n",
    "print(jax.devices())\n"
   ],
   "id": "42c27108c22f222b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "[CudaDevice(id=0)]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:22.580208Z",
     "start_time": "2025-11-18T10:52:22.577784Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] =\"True\"\n",
    "# os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] =\".75\"\n",
    "os.environ[\"TF_GPU_ALLOCATOR\"] =\"cuda_malloc_async\"\n"
   ],
   "id": "73700a3aeb457a0f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:25.216654Z",
     "start_time": "2025-11-18T10:52:23.405910Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Simple transformation - just convert to tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TinyImageNet(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = TinyImageNet(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ],
   "id": "1f6ebf6da8b0b8ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:25.226099Z",
     "start_time": "2025-11-18T10:52:25.222600Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ],
   "id": "655ad8f52f3ccba0",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:27.899496Z",
     "start_time": "2025-11-18T10:52:26.996688Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "# Usage example\n",
    "for images, labels in train_loader:\n",
    "    # Your training code here\n",
    "    print(images.shape, labels.shape)\n",
    "    print(jax.numpy.array(labels).shape)\n",
    "    print(jax.nn.one_hot(jax.numpy.array(labels),200).shape)\n",
    "    print(labels)\n",
    "    # print(jax.nn.one_hot(jax.numpy.array(labels),200))\n",
    "    break"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 64, 64]) torch.Size([8])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.12/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  self.pid = os.fork()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n",
      "(8, 200)\n",
      "tensor([  5,  66, 149,  14,  73, 123, 110, 198])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Resnet Blocks](sources/ResnetPaper.png)\n",
   "id": "f797fa8f260f7fb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building Resnet From Scratch using Equinox\n",
    "Orignal Pytorch Reference : https://github.com/FrancescoSaverioZuppichini/ResNet/blob/master/ResNet.ipynb"
   ],
   "id": "5e0fbdb472f5aafa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:33.868469Z",
     "start_time": "2025-11-18T10:52:33.764118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import equinox as eqx\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from functools import partial\n",
    "eqx.clear_caches()"
   ],
   "id": "4f59dbb48100d04c",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:35.135051Z",
     "start_time": "2025-11-18T10:52:35.075895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED =42\n",
    "key = jrandom.PRNGKey(SEED)"
   ],
   "id": "ed6f4871abbee5b5",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:36.748270Z",
     "start_time": "2025-11-18T10:52:36.745517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== ResNet Basic Block in Equinox (abstract/final; explicit __init__; no object.__setattr__) =====\n",
    "\n",
    "from typing import Optional, Callable\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import jax.random as jr\n"
   ],
   "id": "2e0ac21336250eac",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:38.354569Z",
     "start_time": "2025-11-18T10:52:38.351329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv7x7(eqx.Module):\n",
    "    conv:eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,key):\n",
    "        self.conv = eqx.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=7, stride=2, padding=3,key=key)\n",
    "    def __call__(self,x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "68a2c51cfeaeaece",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:40.207310Z",
     "start_time": "2025-11-18T10:52:39.772045Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy = jr.normal(key,(512,2,2)) #EUREKA MOMENT LOGGED 11/16/25\n",
    "gap = eqx.nn.AdaptiveAvgPool2d(target_shape=(1,1))\n",
    "y = gap(dummy)\n",
    "print(y.shape)"
   ],
   "id": "e18afe5abb768a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 1)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:41.871142Z",
     "start_time": "2025-11-18T10:52:41.867833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv3x3(eqx.Module):\n",
    "    conv:eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.conv = eqx.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=downsample, padding=1,key=key)\n",
    "    def __call__(self,x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "9f4a94625075c847",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:42.837686Z",
     "start_time": "2025-11-18T10:52:42.834364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv_Norm(eqx.Module):\n",
    "    block:eqx.nn.Conv2d\n",
    "    bn :eqx.nn.BatchNorm\n",
    "\n",
    "    def __init__(self,block,bn_channels=8):\n",
    "        self.block = block\n",
    "        self.bn = eqx.nn.BatchNorm(bn_channels,axis_name=\"batch\")\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x = self.block(x)\n",
    "        x,state = self.bn(x,state)\n",
    "        return x,state\n",
    "\n"
   ],
   "id": "37712b5b03e3e6a5",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Resnet Blocks](sources/resnetblocks.png)",
   "id": "e7ad06f4980ced8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:52:45.793056Z",
     "start_time": "2025-11-18T10:52:45.783762Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Residual Blocks\n",
    "class ResBasicBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jax.random.split(key, 3)\n",
    "        c1 = Conv3x3(in_channels,out_channels,downsample,keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=2,key=keys[2])\n",
    "        self.conv1 = Conv_Norm(c1)\n",
    "        self.conv2 = Conv_Norm(c2)\n",
    "        self.shortcut = Conv_Norm(c3)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        residual = x\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        if self.in_channels != self.out_channels or self.downsample==2:\n",
    "            residual,state = self.shortcut(residual,state)\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "class ResBottleNeckBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    conv3: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jr.split(key,4)\n",
    "        c1 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=downsample,key=keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(out_channels,out_channels*4,kernel_size=1,stride=1,key=keys[2])\n",
    "        c4 = eqx.nn.Conv2d(in_channels,out_channels*4,kernel_size=1,stride=1,key=keys[3])\n",
    "        self.conv1 = Conv_Norm(c1,out_channels)\n",
    "        self.conv2 = Conv_Norm(c2,out_channels)\n",
    "        self.conv3 = Conv_Norm(c3,out_channels*4)\n",
    "        self.shortcut = Conv_Norm(c4,out_channels*4)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        residual = x\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv3(x,state)\n",
    "        # jax.debug.print(\"in_channel -> {x}\",x=self.in_channels)\n",
    "        # jax.debug.print(\"out_channel -> {x}\",x=self.out_channels)\n",
    "        # jax.debug.print(\"downsample -> {x}\",x=self.downsample)\n",
    "        if self.in_channels != self.out_channels*4 or self.downsample==2:\n",
    "            residual,state = self.shortcut(residual,state)\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "#Non Residual Blocks\n",
    "class BasicBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jax.random.split(key, 3)\n",
    "        c1 = Conv3x3(in_channels,out_channels,downsample,keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=2,key=keys[2])\n",
    "        self.conv1 = Conv_Norm(c1)\n",
    "        self.conv2 = Conv_Norm(c2)\n",
    "        self.shortcut = Conv_Norm(c3)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "class BottleNeckBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    conv3: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jr.split(key,4)\n",
    "        c1 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=downsample,key=keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(out_channels,out_channels*4,kernel_size=1,stride=1,key=keys[2])\n",
    "        c4 = eqx.nn.Conv2d(in_channels,out_channels*4,kernel_size=1,stride=1,key=keys[3])\n",
    "        self.conv1 = Conv_Norm(c1,out_channels)\n",
    "        self.conv2 = Conv_Norm(c2,out_channels)\n",
    "        self.conv3 = Conv_Norm(c3,out_channels*4)\n",
    "        self.shortcut = Conv_Norm(c4,out_channels*4)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv3(x,state)\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "\n",
    "# module,state = eqx.nn.make_with_state(BottleNeckBlock)(64,64,2,key)\n",
    "# dummy = jr.normal(key,(8,64,8,8))\n",
    "#\n",
    "# batched_forward = eqx.filter_vmap(module, in_axes=(0, None), axis_name=\"batch\")\n",
    "# y, state_batched = batched_forward(dummy, state)\n",
    "# state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "#\n",
    "# print(y.shape)\n"
   ],
   "id": "78794b2c80ecbfb0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__.BottleNeckBlock\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T11:02:23.108304Z",
     "start_time": "2025-11-18T11:02:22.932513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Union\n",
    "\n",
    "class ResNetLayer(eqx.Module):\n",
    "    block: Union[ResBottleNeckBlock,ResBasicBlock,BottleNeckBlock,BasicBlock]\n",
    "    layer:tuple\n",
    "    def __init__(self,in_channels,out_channels,block,key,n=1):\n",
    "        self.block = block\n",
    "        block_expansion = 1 if (issubclass(block,ResBasicBlock) or issubclass(block,BasicBlock)) else 4 #bottleneck has expansion = 4\n",
    "        # jax.debug.print(\"Block Expansion -> {x}\",x=block_expansion)\n",
    "        downsample = 2 if in_channels != out_channels else 1\n",
    "        keys = jr.split(key,n)\n",
    "\n",
    "\n",
    "        blocks = [block(in_channels,out_channels,downsample,keys[0])]\n",
    "\n",
    "        for i in range(1,n):\n",
    "            blocks.append(block(out_channels*block_expansion,out_channels,1,keys[i]))\n",
    "        self.layer = tuple(blocks)\n",
    "\n",
    "    def __call__(self, x,state):\n",
    "        for blk in self.layer:\n",
    "            x, state = blk(x, state)\n",
    "        return x,state\n",
    "\n",
    "\n",
    "module,state = eqx.nn.make_with_state(ResNetLayer)(64,64,BasicBlock,key,n=2)\n",
    "print(sum(x.size for x in jax.tree_util.tree_leaves(eqx.filter(module, eqx.is_array))))\n",
    "dummy = jr.normal(key,(8,64,8,8))\n",
    "\n",
    "batched_forward = eqx.filter_vmap(module, in_axes=(0, None), axis_name=\"batch\")\n",
    "y, state_batched = batched_forward(dummy, state)\n",
    "state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "\n",
    "print(y.shape)\n"
   ],
   "id": "72234ec817eaf0b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156128\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (64,), (8,).",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mTypeError\u001B[39m                                 Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 31\u001B[39m\n\u001B[32m     28\u001B[39m dummy = jr.normal(key,(\u001B[32m8\u001B[39m,\u001B[32m64\u001B[39m,\u001B[32m8\u001B[39m,\u001B[32m8\u001B[39m))\n\u001B[32m     30\u001B[39m batched_forward = eqx.filter_vmap(module, in_axes=(\u001B[32m0\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m), axis_name=\u001B[33m\"\u001B[39m\u001B[33mbatch\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m y, state_batched = \u001B[43mbatched_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     32\u001B[39m state = jax.tree_util.tree_map(\u001B[38;5;28;01mlambda\u001B[39;00m s: s[\u001B[32m0\u001B[39m], state_batched)\n\u001B[32m     34\u001B[39m \u001B[38;5;28mprint\u001B[39m(y.shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/_vmap_pmap.py:169\u001B[39m, in \u001B[36m_VmapWrapper.__call__\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    164\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    165\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mCannot resolve batch dimension. Non-`None` `out_axes` requires \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    166\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33meither `in_axes` or `axis_size` to be not `None`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    167\u001B[39m         )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m     vmapd, nonvmapd_arr, static = \u001B[43mjax\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_fun_wrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m        \u001B[49m\u001B[43min_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mout_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m        \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_axis_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m        \u001B[49m\u001B[43maxis_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_axis_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_vmapkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdynamic_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m nonvmapd_static, out_axes = static.value\n\u001B[32m    179\u001B[39m nonvmapd = combine(nonvmapd_arr, nonvmapd_static)\n",
      "    \u001B[31m[... skipping hidden 8 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mResNetLayer.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x,state):\n\u001B[32m     21\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layer:\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m         x, state = \u001B[43mblk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x,state\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 96\u001B[39m, in \u001B[36mBasicBlock.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m     95\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m,x,state):\n\u001B[32m---> \u001B[39m\u001B[32m96\u001B[39m     x,state = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     97\u001B[39m     x = jax.nn.relu(x)\n\u001B[32m     98\u001B[39m     x,state = \u001B[38;5;28mself\u001B[39m.conv2(x,state)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[13]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mConv_Norm.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m,x,state):\n\u001B[32m     10\u001B[39m     x = \u001B[38;5;28mself\u001B[39m.block(x)\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     x,state = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x,state\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/usr/lib/python3.12/contextlib.py:81\u001B[39m, in \u001B[36mContextDecorator.__call__.<locals>.inner\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m     78\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(*args, **kwds):\n\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._recreate_cm():\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_batch_norm.py:235\u001B[39m, in \u001B[36mBatchNorm.__call__\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    233\u001B[39m running_mean, running_var = state.get(\u001B[38;5;28mself\u001B[39m.ema_state_index)\n\u001B[32m    234\u001B[39m momentum = \u001B[38;5;28mself\u001B[39m.momentum\n\u001B[32m--> \u001B[39m\u001B[32m235\u001B[39m mean = \u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m-\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_mean\u001B[49m\u001B[43m \u001B[49m\u001B[43m+\u001B[49m\u001B[43m \u001B[49m\u001B[43mmomentum\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m \u001B[49m\u001B[43mrunning_mean\u001B[49m\n\u001B[32m    236\u001B[39m var = (\u001B[32m1\u001B[39m - momentum) * batch_var + momentum * running_var\n\u001B[32m    237\u001B[39m \u001B[38;5;66;03m# since jnp.array(0) == False\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/numpy/array_methods.py:604\u001B[39m, in \u001B[36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001B[39m\u001B[34m(self, other)\u001B[39m\n\u001B[32m    602\u001B[39m args = (other, \u001B[38;5;28mself\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m swap \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;28mself\u001B[39m, other)\n\u001B[32m    603\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(other, _accepted_binop_types):\n\u001B[32m--> \u001B[39m\u001B[32m604\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mbinary_op\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    605\u001B[39m \u001B[38;5;66;03m# Note: don't use isinstance here, because we don't want to raise for\u001B[39;00m\n\u001B[32m    606\u001B[39m \u001B[38;5;66;03m# subclasses, e.g. NamedTuple objects that may override operators.\u001B[39;00m\n\u001B[32m    607\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(other) \u001B[38;5;129;01min\u001B[39;00m _rejected_binop_types:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/numpy/ufunc_api.py:183\u001B[39m, in \u001B[36mufunc.__call__\u001B[39m\u001B[34m(self, out, where, *args)\u001B[39m\n\u001B[32m    181\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mwhere argument of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m    182\u001B[39m call = \u001B[38;5;28mself\u001B[39m.__static_props[\u001B[33m'\u001B[39m\u001B[33mcall\u001B[39m\u001B[33m'\u001B[39m] \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._call_vectorized\n\u001B[32m--> \u001B[39m\u001B[32m183\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 13 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/numpy/ufuncs.py:1238\u001B[39m, in \u001B[36madd\u001B[39m\u001B[34m(x, y)\u001B[39m\n\u001B[32m   1236\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m x.dtype == \u001B[38;5;28mbool\u001B[39m:\n\u001B[32m   1237\u001B[39m   \u001B[38;5;28;01mreturn\u001B[39;00m lax.bitwise_or(x, y)\n\u001B[32m-> \u001B[39m\u001B[32m1238\u001B[39m out = \u001B[43mlax\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1239\u001B[39m jnp_error._set_error_if_nan(out)\n\u001B[32m   1240\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "    \u001B[31m[... skipping hidden 13 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/lax/lax.py:136\u001B[39m, in \u001B[36m_try_broadcast_shapes\u001B[39m\u001B[34m(name, *shapes)\u001B[39m\n\u001B[32m    134\u001B[39m       result_shape.append(non_1s[\u001B[32m0\u001B[39m])\n\u001B[32m    135\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m136\u001B[39m       \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m got incompatible shapes for broadcasting: \u001B[39m\u001B[33m'\u001B[39m\n\u001B[32m    137\u001B[39m                       \u001B[33mf\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[33m\"\u001B[39m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m.join(\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mstr\u001B[39m,\u001B[38;5;250m \u001B[39m\u001B[38;5;28mmap\u001B[39m(\u001B[38;5;28mtuple\u001B[39m,\u001B[38;5;250m \u001B[39mshapes)))\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m'\u001B[39m)\n\u001B[32m    138\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mtuple\u001B[39m(result_shape)\n",
      "\u001B[31mTypeError\u001B[39m: add got incompatible shapes for broadcasting: (64,), (8,)."
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:54:47.535727Z",
     "start_time": "2025-11-18T10:54:47.529456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ResNet(eqx.Module):\n",
    "    input_size:int\n",
    "    num_classes:int\n",
    "    layer_size:tuple\n",
    "    layers:tuple\n",
    "    block: callable\n",
    "    maxpool: eqx.nn.MaxPool2d\n",
    "    avgpool: eqx.nn.AdaptiveAvgPool2d\n",
    "    conv1: Conv7x7\n",
    "    fc: eqx.nn.Linear\n",
    "\n",
    "\n",
    "\n",
    "    base_channel: int = 64\n",
    "\n",
    "\n",
    "    def __init__(self,input_size=3,num_classes=200,layer_size=(1,1,1,1),block=ResBasicBlock,key=jax.random.key(0)):\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.layer_size = layer_size\n",
    "        self.block = block\n",
    "        keys = jr.split(key,6)\n",
    "        self.conv1 = Conv7x7(input_size,self.base_channel,keys[0])\n",
    "        self.maxpool = eqx.nn.MaxPool2d(kernel_size=(3,3),stride=(2,2),padding=1)\n",
    "\n",
    "        layers= []\n",
    "        in_channels = self.base_channel\n",
    "        out_channels = self.base_channel\n",
    "        for ii in range(len(layer_size)):\n",
    "            # jax.debug.print(\"Loop Number-> {x}\",x=ii)\n",
    "            layers.append(ResNetLayer(in_channels,out_channels,block,keys[ii+1],layer_size[ii]))\n",
    "            out_channels = in_channels\n",
    "            out_channels = out_channels**(2*ii)\n",
    "        self.layers = tuple(layers)\n",
    "\n",
    "        self.avgpool = eqx.nn.AdaptiveAvgPool2d(target_shape=(1,1))\n",
    "        self.fc = eqx.nn.Linear(out_channels,num_classes,key=keys[-1])\n",
    "\n",
    "    def __call__(self, x,state):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        for layer in self.layers:\n",
    "            x,state = layer(x,state)\n",
    "        x = self.avgpool(x)\n",
    "        x = jnp.ravel(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x,state\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "149ee106e2c6ab2c",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T11:01:43.294277Z",
     "start_time": "2025-11-18T11:01:32.848225Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "module,state = eqx.nn.make_with_state(ResNet)(3,200,(1,1,1,1),ResBasicBlock,key)\n"
   ],
   "id": "968612e62effef07",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1118 04:01:43.179512    1592 bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.00GiB (rounded to 38654705664)requested by op \n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "W1118 04:01:43.179976    1592 bfc_allocator.cc:512] *************************************************************************************_______________\n",
      "E1118 04:01:43.180002    1592 pjrt_stream_executor_client.cc:2974] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes. [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "JaxRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJaxRuntimeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m module,state = \u001B[43meqx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmake_with_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mResNet\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mResBasicBlock\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_stateful.py:366\u001B[39m, in \u001B[36mmake_with_state.<locals>.make_with_state_impl\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmake_with_state_impl\u001B[39m(*args, **kwargs) -> \u001B[38;5;28mtuple\u001B[39m[_T, State]:\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     model = \u001B[43mmake_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    368\u001B[39m     \u001B[38;5;66;03m# Replace all markers with stringified key paths. This is needed to ensure\u001B[39;00m\n\u001B[32m    369\u001B[39m     \u001B[38;5;66;03m# that two calls to `make_with_state` produce compatible models and states.\u001B[39;00m\n\u001B[32m    370\u001B[39m     key_leaves, treedef = jtu.tree_flatten_with_path(model, is_leaf=_is_index)\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[20]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mResNet.__init__\u001B[39m\u001B[34m(self, input_size, num_classes, layer_size, block, key)\u001B[39m\n\u001B[32m     28\u001B[39m out_channels = \u001B[38;5;28mself\u001B[39m.base_channel\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m ii \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(layer_size)):\n\u001B[32m     30\u001B[39m     \u001B[38;5;66;03m# jax.debug.print(\"Loop Number-> {x}\",x=ii)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m     layers.append(\u001B[43mResNetLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[43mii\u001B[49m\u001B[43m+\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlayer_size\u001B[49m\u001B[43m[\u001B[49m\u001B[43mii\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     32\u001B[39m     out_channels = in_channels\n\u001B[32m     33\u001B[39m     out_channels = out_channels**(\u001B[32m2\u001B[39m*ii)\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[26]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mResNetLayer.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, block, key, n)\u001B[39m\n\u001B[32m     10\u001B[39m downsample = \u001B[32m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m in_channels != out_channels \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m1\u001B[39m\n\u001B[32m     11\u001B[39m keys = jr.split(key,n)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m blocks = [\u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m,n):\n\u001B[32m     17\u001B[39m     blocks.append(block(out_channels*block_expansion,out_channels,\u001B[32m1\u001B[39m,keys[i]))\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mResBasicBlock.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, downsample, key)\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28mself\u001B[39m.downsample = downsample\n\u001B[32m     14\u001B[39m keys = jax.random.split(key, \u001B[32m3\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m c1 = \u001B[43mConv3x3\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m c2 = Conv3x3(out_channels,out_channels,\u001B[32m1\u001B[39m,keys[\u001B[32m1\u001B[39m])\n\u001B[32m     17\u001B[39m c3 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=\u001B[32m1\u001B[39m,stride=\u001B[32m2\u001B[39m,key=keys[\u001B[32m2\u001B[39m])\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mConv3x3.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, downsample, key)\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,in_channels,out_channels,downsample,key):\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[38;5;28mself\u001B[39m.conv = \u001B[43meqx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mConv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_conv.py:306\u001B[39m, in \u001B[36mConv2d.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, use_bias, padding_mode, dtype, key)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    293\u001B[39m     in_channels: \u001B[38;5;28mint\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    304\u001B[39m     key: PRNGKeyArray,\n\u001B[32m    305\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_spatial_dims\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m        \u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m        \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_conv.py:172\u001B[39m, in \u001B[36mConv.__init__\u001B[39m\u001B[34m(self, num_spatial_dims, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, use_bias, padding_mode, dtype, key)\u001B[39m\n\u001B[32m    170\u001B[39m lim = \u001B[32m1\u001B[39m / math.sqrt(grouped_in_channels * math.prod(kernel_size))\n\u001B[32m    171\u001B[39m wshape = (out_channels, grouped_in_channels) + kernel_size\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28mself\u001B[39m.weight = \u001B[43mdefault_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    173\u001B[39m bshape = (out_channels,) + (\u001B[32m1\u001B[39m,) * num_spatial_dims\n\u001B[32m    174\u001B[39m \u001B[38;5;28mself\u001B[39m.bias = default_init(bkey, bshape, dtype, lim) \u001B[38;5;28;01mif\u001B[39;00m use_bias \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_misc.py:43\u001B[39m, in \u001B[36mdefault_init\u001B[39m\u001B[34m(key, shape, dtype, lim)\u001B[39m\n\u001B[32m     41\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m real.astype(dtype) + \u001B[32m1\u001B[39mj * imag.astype(dtype)\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjrandom\u001B[49m\u001B[43m.\u001B[49m\u001B[43muniform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminval\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[43mlim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlim\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/random.py:431\u001B[39m, in \u001B[36muniform\u001B[39m\u001B[34m(key, shape, dtype, minval, maxval, out_sharding)\u001B[39m\n\u001B[32m    428\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtypes.issubdtype(dtype, np.floating):\n\u001B[32m    429\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mdtype argument to `uniform` must be a float dtype, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    430\u001B[39m                    \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mgot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m431\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmaybe_auto_axes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_uniform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_sharding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m                       \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 5 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:1378\u001B[39m, in \u001B[36mExecuteReplicated.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1376\u001B[39m   \u001B[38;5;28mself\u001B[39m._handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001B[32m   1377\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1378\u001B[39m   results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mxla_executable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute_sharded\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_bufs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1380\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dispatch.needs_check_special():\n\u001B[32m   1381\u001B[39m   out_arrays = results.disassemble_into_single_device_arrays()\n",
      "\u001B[31mJaxRuntimeError\u001B[39m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes."
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-18T10:53:42.177394Z",
     "start_time": "2025-11-18T10:53:27.998418Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/npedraza/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_batch_norm.py:132: UserWarning: When `eqx.nn.BatchNorm(..., mode=...)` is unspecified it defaults to 'ema', for backward compatibility. This typically has a performance impact, and for new code the user is encouraged to use 'batch' instead. See `https://github.com/patrick-kidger/equinox/issues/659`.\n",
      "  warnings.warn(\n",
      "E1118 03:53:31.365453    1592 gpu_hlo_schedule.cc:817] The byte size of input/output arguments (38654705680) exceeds the base limit (9658466304). This indicates an error in the calculation!\n",
      "W1118 03:53:31.366958    1592 hlo_rematerialization.cc:3204] Can't reduce memory use below 36.00GiB (38654705664 bytes) by rematerialization; only reduced to 36.00GiB (38654706208 bytes), down from 36.00GiB (38654706208 bytes) originally\n",
      "W1118 03:53:41.477556    1592 bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 36.00GiB (rounded to 38654705664)requested by op \n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "W1118 03:53:41.477815    1592 bfc_allocator.cc:512] ********************________________________________________________________________________________\n",
      "E1118 03:53:41.477840    1592 pjrt_stream_executor_client.cc:2974] Execution of replica 0 failed: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes. [tf-allocator-allocation-error='']\n"
     ]
    },
    {
     "ename": "JaxRuntimeError",
     "evalue": "RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mJaxRuntimeError\u001B[39m                           Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m module,state = \u001B[43meqx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mmake_with_state\u001B[49m\u001B[43m(\u001B[49m\u001B[43mResNet\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m200\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mResBasicBlock\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      2\u001B[39m \u001B[38;5;28mprint\u001B[39m(module)\n\u001B[32m      3\u001B[39m dummy = jr.normal(key,(\u001B[32m1\u001B[39m,\u001B[32m3\u001B[39m,\u001B[32m64\u001B[39m,\u001B[32m64\u001B[39m))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_stateful.py:366\u001B[39m, in \u001B[36mmake_with_state.<locals>.make_with_state_impl\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    365\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mmake_with_state_impl\u001B[39m(*args, **kwargs) -> \u001B[38;5;28mtuple\u001B[39m[_T, State]:\n\u001B[32m--> \u001B[39m\u001B[32m366\u001B[39m     model = \u001B[43mmake_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    368\u001B[39m     \u001B[38;5;66;03m# Replace all markers with stringified key paths. This is needed to ensure\u001B[39;00m\n\u001B[32m    369\u001B[39m     \u001B[38;5;66;03m# that two calls to `make_with_state` produce compatible models and states.\u001B[39;00m\n\u001B[32m    370\u001B[39m     key_leaves, treedef = jtu.tree_flatten_with_path(model, is_leaf=_is_index)\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[16]\u001B[39m\u001B[32m, line 31\u001B[39m, in \u001B[36mResNet.__init__\u001B[39m\u001B[34m(self, input_size, num_classes, layer_size, block, key)\u001B[39m\n\u001B[32m     28\u001B[39m out_channels = \u001B[38;5;28mself\u001B[39m.base_channel\n\u001B[32m     29\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m ii \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(layer_size)):\n\u001B[32m     30\u001B[39m     \u001B[38;5;66;03m# jax.debug.print(\"Loop Number-> {x}\",x=ii)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m31\u001B[39m     layers.append(\u001B[43mResNetLayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[43mii\u001B[49m\u001B[43m+\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mlayer_size\u001B[49m\u001B[43m[\u001B[49m\u001B[43mii\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     32\u001B[39m     out_channels = in_channels\n\u001B[32m     33\u001B[39m     out_channels = out_channels**(\u001B[32m2\u001B[39m*ii)\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 14\u001B[39m, in \u001B[36mResNetLayer.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, block, key, n)\u001B[39m\n\u001B[32m     10\u001B[39m downsample = \u001B[32m2\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m in_channels != out_channels \u001B[38;5;28;01melse\u001B[39;00m \u001B[32m1\u001B[39m\n\u001B[32m     11\u001B[39m keys = jr.split(key,n)\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m blocks = [\u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m]\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[32m1\u001B[39m,n):\n\u001B[32m     17\u001B[39m     blocks.append(block(out_channels*block_expansion,out_channels,\u001B[32m1\u001B[39m,keys[i]))\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 15\u001B[39m, in \u001B[36mResBasicBlock.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, downsample, key)\u001B[39m\n\u001B[32m     13\u001B[39m \u001B[38;5;28mself\u001B[39m.downsample = downsample\n\u001B[32m     14\u001B[39m keys = jax.random.split(key, \u001B[32m3\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m15\u001B[39m c1 = \u001B[43mConv3x3\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     16\u001B[39m c2 = Conv3x3(out_channels,out_channels,\u001B[32m1\u001B[39m,keys[\u001B[32m1\u001B[39m])\n\u001B[32m     17\u001B[39m c3 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=\u001B[32m1\u001B[39m,stride=\u001B[32m2\u001B[39m,key=keys[\u001B[32m2\u001B[39m])\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 5\u001B[39m, in \u001B[36mConv3x3.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, downsample, key)\u001B[39m\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m,in_channels,out_channels,downsample,key):\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m     \u001B[38;5;28mself\u001B[39m.conv = \u001B[43meqx\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mConv2d\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdownsample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 2 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_conv.py:306\u001B[39m, in \u001B[36mConv2d.__init__\u001B[39m\u001B[34m(self, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, use_bias, padding_mode, dtype, key)\u001B[39m\n\u001B[32m    291\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__init__\u001B[39m(\n\u001B[32m    292\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    293\u001B[39m     in_channels: \u001B[38;5;28mint\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    304\u001B[39m     key: PRNGKeyArray,\n\u001B[32m    305\u001B[39m ):\n\u001B[32m--> \u001B[39m\u001B[32m306\u001B[39m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[32m    307\u001B[39m \u001B[43m        \u001B[49m\u001B[43mnum_spatial_dims\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m2\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    308\u001B[39m \u001B[43m        \u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43min_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    309\u001B[39m \u001B[43m        \u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m=\u001B[49m\u001B[43mout_channels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    310\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkernel_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    311\u001B[39m \u001B[43m        \u001B[49m\u001B[43mstride\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    312\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    313\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    314\u001B[39m \u001B[43m        \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m=\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    315\u001B[39m \u001B[43m        \u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m=\u001B[49m\u001B[43muse_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    316\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_mode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    317\u001B[39m \u001B[43m        \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    318\u001B[39m \u001B[43m        \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    319\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_conv.py:172\u001B[39m, in \u001B[36mConv.__init__\u001B[39m\u001B[34m(self, num_spatial_dims, in_channels, out_channels, kernel_size, stride, padding, dilation, groups, use_bias, padding_mode, dtype, key)\u001B[39m\n\u001B[32m    170\u001B[39m lim = \u001B[32m1\u001B[39m / math.sqrt(grouped_in_channels * math.prod(kernel_size))\n\u001B[32m    171\u001B[39m wshape = (out_channels, grouped_in_channels) + kernel_size\n\u001B[32m--> \u001B[39m\u001B[32m172\u001B[39m \u001B[38;5;28mself\u001B[39m.weight = \u001B[43mdefault_init\u001B[49m\u001B[43m(\u001B[49m\u001B[43mwkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlim\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    173\u001B[39m bshape = (out_channels,) + (\u001B[32m1\u001B[39m,) * num_spatial_dims\n\u001B[32m    174\u001B[39m \u001B[38;5;28mself\u001B[39m.bias = default_init(bkey, bshape, dtype, lim) \u001B[38;5;28;01mif\u001B[39;00m use_bias \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/equinox/nn/_misc.py:43\u001B[39m, in \u001B[36mdefault_init\u001B[39m\u001B[34m(key, shape, dtype, lim)\u001B[39m\n\u001B[32m     41\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m real.astype(dtype) + \u001B[32m1\u001B[39mj * imag.astype(dtype)\n\u001B[32m     42\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m43\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mjrandom\u001B[49m\u001B[43m.\u001B[49m\u001B[43muniform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminval\u001B[49m\u001B[43m=\u001B[49m\u001B[43m-\u001B[49m\u001B[43mlim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m=\u001B[49m\u001B[43mlim\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/random.py:431\u001B[39m, in \u001B[36muniform\u001B[39m\u001B[34m(key, shape, dtype, minval, maxval, out_sharding)\u001B[39m\n\u001B[32m    428\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m dtypes.issubdtype(dtype, np.floating):\n\u001B[32m    429\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mdtype argument to `uniform` must be a float dtype, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    430\u001B[39m                    \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mgot \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m431\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmaybe_auto_axes\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_uniform\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout_sharding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    432\u001B[39m \u001B[43m                       \u001B[49m\u001B[43mshape\u001B[49m\u001B[43m=\u001B[49m\u001B[43mshape\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m=\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mminval\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxval\u001B[49m\u001B[43m)\u001B[49m\n",
      "    \u001B[31m[... skipping hidden 5 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/jaxvenv2/lib/python3.12/site-packages/jax/_src/interpreters/pxla.py:1378\u001B[39m, in \u001B[36mExecuteReplicated.__call__\u001B[39m\u001B[34m(self, *args)\u001B[39m\n\u001B[32m   1376\u001B[39m   \u001B[38;5;28mself\u001B[39m._handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001B[32m   1377\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1378\u001B[39m   results = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mxla_executable\u001B[49m\u001B[43m.\u001B[49m\u001B[43mexecute_sharded\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_bufs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1380\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m dispatch.needs_check_special():\n\u001B[32m   1381\u001B[39m   out_arrays = results.disassemble_into_single_device_arrays()\n",
      "\u001B[31mJaxRuntimeError\u001B[39m: RESOURCE_EXHAUSTED: Out of memory while trying to allocate 38654705664 bytes."
     ]
    }
   ],
   "execution_count": 17,
   "source": [
    "print(module)\n",
    "dummy = jr.normal(key,(1,3,64,64))\n",
    "batched_forward = eqx.filter_vmap(module, in_axes=(0, None), axis_name=\"batch\")\n",
    "y, state_batched = batched_forward(dummy, state)\n",
    "state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "111a709d973ddf19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7f27cec02c1f2aec",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

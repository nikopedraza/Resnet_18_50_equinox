{
 "cells": [
  {
   "cell_type": "code",
   "id": "c1a46fd3b0556119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:54:55.517984Z",
     "start_time": "2025-11-20T05:54:49.550514Z"
    }
   },
   "source": [
    "import torch\n",
    "import jax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tiny_imagenet_torch import TinyImageNet ## Import allow TinyImage via torch methods(64x64)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T03:45:58.250673Z",
     "start_time": "2025-11-20T03:45:58.208744Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Confirm cuda is enabled on both jax and torch\n",
    "print(torch.cuda.is_available())\n",
    "print(jax.devices())\n"
   ],
   "id": "42c27108c22f222b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "[CpuDevice(id=0)]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:35.153797Z",
     "start_time": "2025-11-20T05:55:34.837872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Simple transformation - just convert to tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Create dataset\n",
    "train_dataset = TinyImageNet(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = TinyImageNet(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")"
   ],
   "id": "1f6ebf6da8b0b8ae",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:35.779336Z",
     "start_time": "2025-11-20T05:55:35.775056Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=4)"
   ],
   "id": "655ad8f52f3ccba0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:48.483849Z",
     "start_time": "2025-11-20T05:55:36.507445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jax\n",
    "# Usage example\n",
    "for images, labels in train_loader:\n",
    "    # Your training code here\n",
    "    print(images.shape, labels.shape)\n",
    "    print(jax.numpy.array(labels).shape)\n",
    "    print(jax.nn.one_hot(jax.numpy.array(labels),200).shape)\n",
    "    print(labels)\n",
    "    # print(jax.nn.one_hot(jax.numpy.array(labels),200))\n",
    "    break"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3, 64, 64]) torch.Size([8])\n",
      "(8,)\n",
      "(8, 200)\n",
      "tensor([ 75,  49, 192,  62,  28,  16,  30, 158])\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Resnet Blocks](sources/ResnetPaper.png)\n",
   "id": "f797fa8f260f7fb0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Building Resnet From Scratch using Equinox\n",
    "Orignal Pytorch Reference : https://github.com/FrancescoSaverioZuppichini/ResNet/blob/master/ResNet.ipynb"
   ],
   "id": "5e0fbdb472f5aafa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:48.961099Z",
     "start_time": "2025-11-20T05:55:48.823655Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import equinox as eqx\n",
    "import jax.nn as jnn\n",
    "import jax.numpy as jnp\n",
    "import jax.random as jrandom\n",
    "from functools import partial\n",
    "eqx.clear_caches()"
   ],
   "id": "4f59dbb48100d04c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:49.456663Z",
     "start_time": "2025-11-20T05:55:49.419445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "SEED =42\n",
    "key = jrandom.PRNGKey(SEED)"
   ],
   "id": "ed6f4871abbee5b5",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:50.003950Z",
     "start_time": "2025-11-20T05:55:50.000718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ===== ResNet Basic Block in Equinox (abstract/final; explicit __init__; no object.__setattr__) =====\n",
    "\n",
    "from typing import Optional, Callable\n",
    "import equinox as eqx\n",
    "import jax.numpy as jnp\n",
    "import jax.nn as jnn\n",
    "import jax.random as jr\n"
   ],
   "id": "2e0ac21336250eac",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:50.674037Z",
     "start_time": "2025-11-20T05:55:50.668807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv7x7(eqx.Module):\n",
    "    conv:eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,key):\n",
    "        self.conv = eqx.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=7, stride=2, padding=3,key=key)\n",
    "    def __call__(self,x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "68a2c51cfeaeaece",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:51.615929Z",
     "start_time": "2025-11-20T05:55:51.251284Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dummy = jr.normal(key,(512,2,2)) #EUREKA MOMENT LOGGED 11/16/25\n",
    "gap = eqx.nn.AdaptiveAvgPool2d(target_shape=(1,1))\n",
    "y = gap(dummy)\n",
    "print(y.shape)"
   ],
   "id": "e18afe5abb768a83",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 1, 1)\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:52.447757Z",
     "start_time": "2025-11-20T05:55:52.443406Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv3x3(eqx.Module):\n",
    "    conv:eqx.nn.Conv2d\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.conv = eqx.nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=downsample, padding=1,key=key)\n",
    "    def __call__(self,x):\n",
    "        return self.conv(x)\n"
   ],
   "id": "9f4a94625075c847",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:53.190516Z",
     "start_time": "2025-11-20T05:55:53.186993Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Conv_Norm(eqx.Module):\n",
    "    block:eqx.nn.Conv2d\n",
    "    bn :eqx.nn.BatchNorm\n",
    "\n",
    "    def __init__(self,block,bn_channels):\n",
    "        self.block = block\n",
    "        self.bn = eqx.nn.BatchNorm(bn_channels,axis_name=\"batch\",mode=\"batch\")\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x = self.block(x)\n",
    "        x,state = self.bn(x,state)\n",
    "        return x,state\n",
    "\n"
   ],
   "id": "37712b5b03e3e6a5",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "![Resnet Blocks](sources/resnetblocks.png)",
   "id": "e7ad06f4980ced8a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:55.135033Z",
     "start_time": "2025-11-20T05:55:55.128268Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Residual Blocks\n",
    "class ResBasicBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    shortcut: Conv_Norm\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    downsample: int\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, downsample, key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "\n",
    "        k1, k2, k3, _ = jax.random.split(key, 4)\n",
    "\n",
    "        # Main path\n",
    "        c1 = Conv3x3(in_channels, out_channels, downsample, k1)\n",
    "        c2 = Conv3x3(out_channels, out_channels, 1,        k2)\n",
    "\n",
    "        self.conv1 = Conv_Norm(c1, out_channels)\n",
    "        self.conv2 = Conv_Norm(c2, out_channels)\n",
    "\n",
    "        # Shortcut path: only *needed* when channels or stride change,\n",
    "        # but it's fine to always create it and only sometimes use it.\n",
    "        c3 = eqx.nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            stride=downsample,\n",
    "            padding=0,\n",
    "            key=k3,\n",
    "        )\n",
    "        self.shortcut = Conv_Norm(c3, out_channels)\n",
    "\n",
    "    def __call__(self, x, state):\n",
    "        residual = x\n",
    "\n",
    "        x, state = self.conv1(x, state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x, state = self.conv2(x, state)\n",
    "\n",
    "        jax.debug.print(\"Block in channels -> {x}\", x=self.in_channels)\n",
    "        jax.debug.print(\"Block out channels -> {x}\", x=self.out_channels)\n",
    "        jax.debug.print(\"downsample -> {x}\", x=self.downsample)\n",
    "\n",
    "        # Use shortcut if shape would differ\n",
    "        if self.in_channels != self.out_channels or self.downsample == 2:\n",
    "            jax.debug.print(\"here\")\n",
    "            residual, state = self.shortcut(residual, state)\n",
    "\n",
    "        x = x + residual\n",
    "        return jax.nn.relu(x), state\n",
    "\n",
    "\n",
    "class ResBottleNeckBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    conv3: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jr.split(key,3)\n",
    "        c1 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=downsample,key=keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(out_channels,out_channels*4,kernel_size=1,stride=1,key=keys[2])\n",
    "        c4 = eqx.nn.Conv2d(in_channels,out_channels*4,kernel_size=1,stride=downsample,key=keys[3])\n",
    "        self.conv1 = Conv_Norm(c1,out_channels)\n",
    "        self.conv2 = Conv_Norm(c2,out_channels)\n",
    "        self.conv3 = Conv_Norm(c3,out_channels*4)\n",
    "        self.shortcut = Conv_Norm(c4,out_channels*4)\n",
    "\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        residual = x\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv3(x,state)\n",
    "        # jax.debug.print(\"in_channel -> {x}\",x=self.in_channels)\n",
    "        # jax.debug.print(\"out_channel -> {x}\",x=self.out_channels)\n",
    "        # jax.debug.print(\"downsample -> {x}\",x=self.downsample)\n",
    "        if self.in_channels != self.out_channels*4 or self.downsample==2:\n",
    "            residual,state = self.shortcut(residual,state)\n",
    "\n",
    "        x = x + residual\n",
    "\n",
    "        return jax.nn.relu(x),state"
   ],
   "id": "78794b2c80ecbfb0",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:56.230093Z",
     "start_time": "2025-11-20T05:55:56.221932Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "#Non Residual Blocks\n",
    "class BasicBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jax.random.split(key, 3)\n",
    "        c1 = Conv3x3(in_channels,out_channels,downsample,keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=downsample,key=keys[2])\n",
    "        self.conv1 = Conv_Norm(c1,out_channels)\n",
    "        self.conv2 = Conv_Norm(c2,out_channels)\n",
    "        self.shortcut = Conv_Norm(c3,out_channels)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "class BottleNeckBlock(eqx.Module):\n",
    "    conv1: Conv_Norm\n",
    "    conv2: Conv_Norm\n",
    "    conv3: Conv_Norm\n",
    "    shortcut:Conv_Norm\n",
    "    in_channels:int\n",
    "    out_channels:int\n",
    "    downsample:int\n",
    "\n",
    "    def __init__(self,in_channels,out_channels,downsample,key):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.downsample = downsample\n",
    "        keys = jr.split(key,4)\n",
    "        c1 = eqx.nn.Conv2d(in_channels,out_channels,kernel_size=1,stride=downsample,key=keys[0])\n",
    "        c2 = Conv3x3(out_channels,out_channels,1,keys[1])\n",
    "        c3 = eqx.nn.Conv2d(out_channels,out_channels*4,kernel_size=1,stride=1,key=keys[2])\n",
    "        c4 = eqx.nn.Conv2d(in_channels,out_channels*4,kernel_size=1,stride=downsample,key=keys[3])\n",
    "        self.conv1 = Conv_Norm(c1,out_channels)\n",
    "        self.conv2 = Conv_Norm(c2,out_channels)\n",
    "        self.conv3 = Conv_Norm(c3,out_channels*4)\n",
    "        self.shortcut = Conv_Norm(c4,out_channels*4)\n",
    "\n",
    "    def __call__(self,x,state):\n",
    "        x,state = self.conv1(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv2(x,state)\n",
    "        x = jax.nn.relu(x)\n",
    "        x,state = self.conv3(x,state)\n",
    "        return jax.nn.relu(x),state\n",
    "\n",
    "eqx.tree_pprint(BottleNeckBlock)\n",
    "\n",
    "# module,state = eqx.nn.make_with_state(BottleNeckBlock)(64,64,2,key)\n",
    "# dummy = jr.normal(key,(8,64,8,8))\n",
    "#\n",
    "# batched_forward = eqx.filter_vmap(module, in_axes=(0, None), axis_name=\"batch\")\n",
    "# y, state_batched = batched_forward(dummy, state)\n",
    "# state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "#\n",
    "# print(y.shape)\n"
   ],
   "id": "b78e0f50bfd070fe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__main__.BottleNeckBlock\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:56.857034Z",
     "start_time": "2025-11-20T05:55:56.851855Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Union\n",
    "\n",
    "class ResNetLayer(eqx.Module):\n",
    "    block: Union[ResBottleNeckBlock,ResBasicBlock,BottleNeckBlock,BasicBlock]\n",
    "    layer:tuple\n",
    "    def __init__(self,in_channels,out_channels,block,key,n=1):\n",
    "        self.block = block\n",
    "        block_expansion = 1 if issubclass(block,(ResBasicBlock,BasicBlock))  else 4 #bottleneck has expansion = 4\n",
    "        # jax.debug.print(\"Block Expansion -> {x}\",x=block_expansion)\n",
    "        downsample = 2 if in_channels != out_channels*block_expansion else 1\n",
    "        keys = jr.split(key,n)\n",
    "\n",
    "        jax.debug.print(\"Layer Downsample -> {x}\",x=downsample)\n",
    "        blocks = [block(in_channels,out_channels,downsample,keys[0])]\n",
    "\n",
    "        for i in range(1,n):\n",
    "            blocks.append(block(out_channels*block_expansion,out_channels,1,keys[i]))\n",
    "        self.layer = tuple(blocks)\n",
    "\n",
    "    def __call__(self, x,state):\n",
    "        for blk in self.layer:\n",
    "            x, state = blk(x, state)\n",
    "        return x,state\n",
    "\n",
    "\n",
    "# eqx.tree_pprint(ResNetLayer)\n",
    "# module,state = eqx.nn.make_with_state(ResNetLayer)(64,64,BottleNeckBlock,key,n=3)\n",
    "# dummy = jr.normal(key,(8,64,8,8))\n",
    "#\n",
    "# batched_forward = eqx.filter_vmap(module, in_axes=(0, None), axis_name=\"batch\")\n",
    "# y, state_batched = batched_forward(dummy, state)\n",
    "# state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "#\n",
    "# print(y.shape)\n",
    "# print(state)"
   ],
   "id": "72234ec817eaf0b0",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:55:57.445803Z",
     "start_time": "2025-11-20T05:55:57.436261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class ResNet(eqx.Module):\n",
    "    input_size:int\n",
    "    num_classes:int\n",
    "    layer_size:tuple\n",
    "    layers:tuple\n",
    "    block: Union[ResBasicBlock,ResBottleNeckBlock,BottleNeckBlock,BasicBlock]\n",
    "    maxpool: eqx.nn.MaxPool2d\n",
    "    avgpool: eqx.nn.AdaptiveAvgPool2d\n",
    "    conv1: Conv7x7\n",
    "    fc: eqx.nn.Linear\n",
    "\n",
    "\n",
    "\n",
    "    base_channel: int = 64\n",
    "\n",
    "\n",
    "    def __init__(self,input_size=3,num_classes=200,layer_size=(1,1,1,1),block=ResBasicBlock,key=jax.random.key(0)):\n",
    "        self.input_size = input_size\n",
    "        self.num_classes = num_classes\n",
    "        self.layer_size = layer_size\n",
    "        self.block = block\n",
    "        keys = jr.split(key,6)\n",
    "        block_expansion = 1 if (issubclass(block, ResBasicBlock) or issubclass(block, BasicBlock)) else 4\n",
    "        self.conv1 = Conv7x7(input_size,self.base_channel,keys[0])\n",
    "        self.maxpool = eqx.nn.MaxPool2d(kernel_size=(3,3),stride=(2,2),padding=1)\n",
    "\n",
    "        in_channels = self.base_channel\n",
    "        out_channels = self.base_channel\n",
    "        jax.debug.print(\"Layer0 in channels -> {x}\",x=in_channels)\n",
    "        jax.debug.print(\"Layer0 out channels -> {x}\",x=out_channels)\n",
    "        layers= [ResNetLayer(in_channels,out_channels,block,keys[1],layer_size[0])]\n",
    "        # jax.debug.print(\"Layer0 in channels -> {x}\",x=in_channels)\n",
    "        # jax.debug.print(\"Layer0 out channels -> {x}\",x=out_channels)\n",
    "        for ii in range(1,len(layer_size)):\n",
    "            # jax.debug.print(\"in channels -> {x}\",x=in_channels)\n",
    "            # jax.debug.print(\"out channels -> {x}\",x=out_channels)\n",
    "            out_channels = 2*in_channels\n",
    "            jax.debug.print(\"Layer{i} in channels -> {x}\",x=in_channels,i=ii)\n",
    "            jax.debug.print(\"Layer{i} out channels -> {x}\",x=out_channels,i=ii)\n",
    "            layers.append(ResNetLayer(in_channels,out_channels,block,keys[ii+1],layer_size[ii]))\n",
    "            in_channels = out_channels*block_expansion\n",
    "\n",
    "            # jax.debug.print(\"Layer{i} in channels -> {x}\",x=in_channels,i=ii)\n",
    "            # jax.debug.print(\"Layer{i} out channels -> {x}\",x=out_channels,i=ii)\n",
    "\n",
    "\n",
    "            #jax.debug.print(\"Loop Number-> {x}\",x=ii)\n",
    "\n",
    "        self.layers = tuple(layers)\n",
    "\n",
    "        self.avgpool = eqx.nn.AdaptiveAvgPool2d(target_shape=(1,1))\n",
    "        self.fc = eqx.nn.Linear(out_channels,num_classes,key=keys[-1])\n",
    "\n",
    "    def __call__(self, x,state):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        for i,layer in enumerate(self.layers):\n",
    "            # if i >= 1:\n",
    "                # jax.debug.print(\"iteration -> {x}\",x=i)\n",
    "                # jax.debug.print(\"layer -> {x}\",x=layer)\n",
    "            x,state = layer(x,state)\n",
    "            jax.debug.print(\"x shape -> {x}\",x=x.shape)\n",
    "\n",
    "\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = jnp.ravel(x)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x,state\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "149ee106e2c6ab2c",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T05:57:29.567922Z",
     "start_time": "2025-11-20T05:56:50.020287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "module,state = eqx.nn.make_with_state(ResNet)(3,200,(2,2,2,2),ResBottleNeckBlock,key)\n",
    "dummy = jr.normal(key,(1,3,64,64))\n",
    "\n",
    "batched_forward = eqx.filter_vmap(module, in_axes=(0,None),axis_name=\"batch\")\n",
    "y, state_batched = batched_forward(dummy, state)\n",
    "state = jax.tree_util.tree_map(lambda s: s[0], state_batched)\n",
    "\n",
    "print(y.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "111a709d973ddf19",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer0 in channels -> 64\n",
      "Layer0 out channels -> 64\n",
      "Layer Downsample -> 2\n",
      "Layer1 in channels -> 64\n",
      "Layer1 out channels -> 128\n",
      "Layer Downsample -> 2\n",
      "Layer2 in channels -> 512\n",
      "Layer2 out channels -> 1024\n",
      "Layer Downsample -> 2\n",
      "Layer3 in channels -> 4096\n",
      "Layer3 out channels -> 8192\n",
      "Layer Downsample -> 2\n",
      "x shape -> (Array(256, dtype=int32, weak_type=True), Array(8, dtype=int32, weak_type=True), Array(8, dtype=int32, weak_type=True))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "conv_general_dilated lhs feature dimension size divided by feature_group_count must equal the rhs input feature dimension size, but 256 // 1 != 64.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[17]\u001B[39m\u001B[32m, line 5\u001B[39m\n\u001B[32m      2\u001B[39m dummy = jr.normal(key,(\u001B[32m1\u001B[39m,\u001B[32m3\u001B[39m,\u001B[32m64\u001B[39m,\u001B[32m64\u001B[39m))\n\u001B[32m      4\u001B[39m batched_forward = eqx.filter_vmap(module, in_axes=(\u001B[32m0\u001B[39m,\u001B[38;5;28;01mNone\u001B[39;00m),axis_name=\u001B[33m\"\u001B[39m\u001B[33mbatch\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m5\u001B[39m y, state_batched = \u001B[43mbatched_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdummy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      6\u001B[39m state = jax.tree_util.tree_map(\u001B[38;5;28;01mlambda\u001B[39;00m s: s[\u001B[32m0\u001B[39m], state_batched)\n\u001B[32m      8\u001B[39m \u001B[38;5;28mprint\u001B[39m(y.shape)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\equinox\\_vmap_pmap.py:169\u001B[39m, in \u001B[36m_VmapWrapper.__call__\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    164\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m    165\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mCannot resolve batch dimension. Non-`None` `out_axes` requires \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    166\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33meither `in_axes` or `axis_size` to be not `None`.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    167\u001B[39m         )\n\u001B[32m    168\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m169\u001B[39m     vmapd, nonvmapd_arr, static = \u001B[43mjax\u001B[49m\u001B[43m.\u001B[49m\u001B[43mvmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    170\u001B[39m \u001B[43m        \u001B[49m\u001B[43m_fun_wrapper\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    171\u001B[39m \u001B[43m        \u001B[49m\u001B[43min_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[43min_axes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    172\u001B[39m \u001B[43m        \u001B[49m\u001B[43mout_axes\u001B[49m\u001B[43m=\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    173\u001B[39m \u001B[43m        \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_axis_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    174\u001B[39m \u001B[43m        \u001B[49m\u001B[43maxis_size\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_axis_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    175\u001B[39m \u001B[43m        \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_vmapkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    176\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdynamic_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    178\u001B[39m nonvmapd_static, out_axes = static.value\n\u001B[32m    179\u001B[39m nonvmapd = combine(nonvmapd_arr, nonvmapd_static)\n",
      "    \u001B[31m[... skipping hidden 8 frame]\u001B[39m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[15]\u001B[39m\u001B[32m, line 62\u001B[39m, in \u001B[36mResNet.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m     56\u001B[39m x = \u001B[38;5;28mself\u001B[39m.maxpool(x)\n\u001B[32m     58\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i,layer \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m.layers):\n\u001B[32m     59\u001B[39m     \u001B[38;5;66;03m# if i >= 1:\u001B[39;00m\n\u001B[32m     60\u001B[39m         \u001B[38;5;66;03m# jax.debug.print(\"iteration -> {x}\",x=i)\u001B[39;00m\n\u001B[32m     61\u001B[39m         \u001B[38;5;66;03m# jax.debug.print(\"layer -> {x}\",x=layer)\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m62\u001B[39m     x,state = \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     63\u001B[39m     jax.debug.print(\u001B[33m\"\u001B[39m\u001B[33mx shape -> \u001B[39m\u001B[38;5;132;01m{x}\u001B[39;00m\u001B[33m\"\u001B[39m,x=x.shape)\n\u001B[32m     67\u001B[39m x = \u001B[38;5;28mself\u001B[39m.avgpool(x)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[14]\u001B[39m\u001B[32m, line 22\u001B[39m, in \u001B[36mResNetLayer.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, x,state):\n\u001B[32m     21\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m blk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.layer:\n\u001B[32m---> \u001B[39m\u001B[32m22\u001B[39m         x, state = \u001B[43mblk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     23\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x,state\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 82\u001B[39m, in \u001B[36mResBottleNeckBlock.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m     80\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m,x,state):\n\u001B[32m     81\u001B[39m     residual = x\n\u001B[32m---> \u001B[39m\u001B[32m82\u001B[39m     x,state = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mconv1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     83\u001B[39m     x = jax.nn.relu(x)\n\u001B[32m     84\u001B[39m     x,state = \u001B[38;5;28mself\u001B[39m.conv2(x,state)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[11]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mConv_Norm.__call__\u001B[39m\u001B[34m(self, x, state)\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m,x,state):\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mblock\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     11\u001B[39m     x,state = \u001B[38;5;28mself\u001B[39m.bn(x,state)\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m x,state\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\Python312\\Lib\\contextlib.py:81\u001B[39m, in \u001B[36mContextDecorator.__call__.<locals>.inner\u001B[39m\u001B[34m(*args, **kwds)\u001B[39m\n\u001B[32m     78\u001B[39m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[32m     79\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34minner\u001B[39m(*args, **kwds):\n\u001B[32m     80\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m._recreate_cm():\n\u001B[32m---> \u001B[39m\u001B[32m81\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\equinox\\nn\\_conv.py:238\u001B[39m, in \u001B[36mConv.__call__\u001B[39m\u001B[34m(self, x, key)\u001B[39m\n\u001B[32m    235\u001B[39m     padding = \u001B[38;5;28mself\u001B[39m.padding\n\u001B[32m    237\u001B[39m x = jnp.expand_dims(x, axis=\u001B[32m0\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m238\u001B[39m x = \u001B[43mlax\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconv_general_dilated\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    239\u001B[39m \u001B[43m    \u001B[49m\u001B[43mlhs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    240\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrhs\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    241\u001B[39m \u001B[43m    \u001B[49m\u001B[43mwindow_strides\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mstride\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    242\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    243\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrhs_dilation\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdilation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    244\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfeature_group_count\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    245\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    246\u001B[39m x = jnp.squeeze(x, axis=\u001B[32m0\u001B[39m)\n\u001B[32m    248\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.use_bias:\n",
      "    \u001B[31m[... skipping hidden 37 frame]\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\jax\\_src\\lax\\convolution.py:377\u001B[39m, in \u001B[36m_conv_general_dilated_shape_rule\u001B[39m\u001B[34m(lhs, rhs, window_strides, padding, lhs_dilation, rhs_dilation, dimension_numbers, feature_group_count, batch_group_count, **unused_kwargs)\u001B[39m\n\u001B[32m    373\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m core.definitely_equal(quot, rhs.shape[dimension_numbers.rhs_spec[\u001B[32m1\u001B[39m]]):\n\u001B[32m    374\u001B[39m   msg = (\u001B[33m\"\u001B[39m\u001B[33mconv_general_dilated lhs feature dimension size divided by \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    375\u001B[39m          \u001B[33m\"\u001B[39m\u001B[33mfeature_group_count must equal the rhs input feature dimension \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    376\u001B[39m          \u001B[33m\"\u001B[39m\u001B[33msize, but \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m // \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m != \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m377\u001B[39m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg.format(lhs_feature_count, feature_group_count,\n\u001B[32m    378\u001B[39m                               rhs.shape[dimension_numbers.rhs_spec[\u001B[32m1\u001B[39m]]))\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m rhs.shape[dimension_numbers.rhs_spec[\u001B[32m0\u001B[39m]] % feature_group_count:\n\u001B[32m    380\u001B[39m   msg = (\u001B[33m\"\u001B[39m\u001B[33mconv_general_dilated rhs output feature dimension size must be a \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    381\u001B[39m          \u001B[33m\"\u001B[39m\u001B[33mmultiple of feature_group_count, but \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m is not a multiple of \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m.\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[31mValueError\u001B[39m: conv_general_dilated lhs feature dimension size divided by feature_group_count must equal the rhs input feature dimension size, but 256 // 1 != 64."
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-20T04:58:54.088998Z",
     "start_time": "2025-11-20T04:58:54.087143Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7f27cec02c1f2aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a6c6ede60fc56450"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
